{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSSD: Semantic Search Stance Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path of your files in local file system\n",
    "query_set_path = './data/processed/vaccination/query_set.csv'\n",
    "test_set_path = './data/processed/vaccination/test_set.csv'\n",
    "domain_set_path = './data/processed/vaccination/domain_set.csv'\n",
    "\n",
    "# Loading a manually labeled dataset containing representative tweets\n",
    "# of different stances on vaccination. This set is useful for training and\n",
    "# evaluating natural language processing models, providing concrete examples\n",
    "# of how different opinions are expressed on Twitter.\n",
    "query_set = pd.read_csv(query_set_path)\n",
    "\n",
    "# Loading a test dataset, also manually labeled, used\n",
    "# to test the generalization and effectiveness of natural language processing models.\n",
    "# This set helps evaluate how the model performs in relation to new\n",
    "# data and examples that were not seen during training.\n",
    "test_set = pd.read_csv(test_set_path)\n",
    "\n",
    "# The domain_set is presumed to be a larger set of tweets collected using hashttags for analysis.\n",
    "domain_set = pd.read_csv(domain_set_path)\n",
    "\n",
    "# Removing texts from the combined DataFrame that are present in the query_set or test_set,\n",
    "# ensuring the uniqueness and integrity of the domain_set.\n",
    "# This step is crucial to maintain the separation between training, testing, and domain-specific datasets.\n",
    "domain_set = domain_set[~domain_set.text.isin(query_set.text)]\n",
    "domain_set = domain_set[~domain_set.text.isin(test_set.text)]\n",
    "domain_set.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Semantic Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_labeling(domain_set, ptm, domain_set_embeddings, query_set, top_k):\n",
    "    \"\"\"\n",
    "    Function for semantic labeling of a corpus using a pre-trained Transformer model (PTM).\n",
    "\n",
    "    Args:\n",
    "        domain_set (DataFrame): A DataFrame containing the data to be labeled. Must have 'id' and 'text' columns.\n",
    "        ptm (SentenceTransformer): The pre-trained Transformer model used to generate embeddings.\n",
    "        domain_set_embeddings (Tensor): Embeddings of the domain set generated by the PTM.\n",
    "        query_set (DataFrame): A DataFrame containing reference queries and their associated labels.\n",
    "        top_k (int): The number of top results to be considered for each query.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A new DataFrame with the texts of the corpus labeled based on semantic similarity\n",
    "        to the queries in query_set.\n",
    "\n",
    "    Process:\n",
    "        1. For each query in the query_set, compute its embedding using the PTM.\n",
    "        2. Calculate the cosine similarity between the query embedding and the embeddings of the domain_set.\n",
    "        3. Select the top_k results based on the highest similarity.\n",
    "        4. For each of the top results, create a dictionary containing 'id', 'query', 'text', 'label', \n",
    "           and 'score' (cosine similarity).\n",
    "        5. Add each dictionary to a list.\n",
    "        6. Convert the list of dictionaries into a DataFrame and return it.\n",
    "    \"\"\"\n",
    "    k = min(top_k, len(domain_set))\n",
    "    labeled_list = []\n",
    "\n",
    "    for query in query_set.values:\n",
    "        # Generate embeddings for the query using the PTM.\n",
    "        query_embeddings = ptm.encode(query[0], convert_to_tensor=True)\n",
    "        # Calculate the cosine similarity between the query and the domain set.\n",
    "        cos_scores = util.cos_sim(query_embeddings, domain_set_embeddings)[0]\n",
    "        # Select the top_k results based on the scores.\n",
    "        top_results = torch.topk(cos_scores, k=k)\n",
    "\n",
    "        for score, idx in zip(top_results[0], top_results[1]):\n",
    "            # Create a dictionary with the relevant details and add it to the list.\n",
    "            docs = {\n",
    "                \"id\": domain_set.id[idx.cpu().detach().numpy()],\n",
    "                \"query\": query[0],\n",
    "                \"text\": domain_set.text[idx.cpu().detach().numpy()],\n",
    "                \"label\": query[1],\n",
    "                \"score\": np.round(score.cpu().detach().numpy(), 2)\n",
    "            }\n",
    "            labeled_list.append(docs)\n",
    "\n",
    "    # Convert the list of dictionaries into a DataFrame and return it.\n",
    "    return pd.DataFrame(labeled_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Sentence Transformer model for generating embeddings, using 'all-MiniLM-L6-v2'.\n",
    "# The model is configured to use GPU ('cuda') for accelerated processing.\n",
    "ptm = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n",
    "\n",
    "# Generate embeddings for the 'domain_set' dataset using the loaded model.\n",
    "# Conversion to PyTorch tensor is enabled for improved performance in subsequent operations.\n",
    "domain_set['text'] = domain_set.text.astype('str')\n",
    "domain_set_embeddings = ptm.encode(domain_set.text, convert_to_tensor=True)\n",
    "\n",
    "# Loop to process semantic labeling for different sizes of top results (k).\n",
    "# The tqdm progress bar is used to track progress over the range of k values.\n",
    "for k in tqdm(range(5, 105, 5), desc=\"Do queries with k values\"):\n",
    "    # Generates a semantically labeled dataset based on 'k' top results.\n",
    "    k_tweets = semantic_labeling(domain_set, ptm, domain_set_embeddings, query_set, k)\n",
    "\n",
    "    # Filter to keep only entries with a cosine max similarity score threshold  <= 0.95.\n",
    "    # This helps to avoid including highly similar results that could bias the model.\n",
    "    k_tweets = k_tweets[k_tweets.score <= 0.95]\n",
    "\n",
    "    # Saves the augmented dataset in a CSV file.\n",
    "    # The file name includes the value of 'k' for easy reference.\n",
    "    k_tweets.to_csv(f'./data/labeled/vaccination/{k}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Stance Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "\n",
    "# Initialize parameters for the TF-IDF vectorizer.\n",
    "NGRAM_RANGE = (1, 2)\n",
    "TOKEN_MODE = 'word'\n",
    "MIN_DOCUMENT_FREQUENCY = 2\n",
    "kwargs = {\n",
    "    'ngram_range': NGRAM_RANGE,\n",
    "    'strip_accents': 'unicode',\n",
    "    'decode_error': 'replace',\n",
    "    'analyzer': TOKEN_MODE,\n",
    "    'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "}\n",
    "\n",
    "# DataFrame to accumulate classification reports.\n",
    "all_metrics = pd.DataFrame()\n",
    "\n",
    "# Loop over different values of k.\n",
    "for k in tqdm(range(5, 105, 5), desc=\"Training SD Models\"):\n",
    "    # Load the training set for the current value of k.\n",
    "    training_set = pd.read_csv(f'./data/labeled/vaccination/{k}.csv')\n",
    "    training_set['subset'] = 'train'\n",
    "    training_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Prepare the test set.\n",
    "    test_set['subset'] = 'test'\n",
    "    test_set = test_set[['text', 'label', 'subset']]\n",
    "    test_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Concatenate the training and test sets.\n",
    "    train_test_set = pd.concat([training_set, test_set])\n",
    "    train_test_set.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Vectorize the data.\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "    X = vectorizer.fit_transform(train_test_set.text)\n",
    "\n",
    "    # Select the training and test subsets.\n",
    "    X_train = X[train_test_set[train_test_set.subset == 'train'].index]\n",
    "    y_train = train_test_set[train_test_set.subset == 'train'].label\n",
    "\n",
    "    X_test = X[train_test_set[train_test_set.subset == 'test'].index]\n",
    "    y_test = train_test_set[train_test_set.subset == 'test'].label\n",
    "\n",
    "    # Train and predict with the model.\n",
    "    model = LogisticRegression(class_weight=\"balanced\", solver=\"liblinear\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Generate the classification report (MLFlow recommended for logging).\n",
    "    clf_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    report = pd.DataFrame(clf_report).transpose()\n",
    "\n",
    "    # Create a temporary DataFrame to store the metrics for the current k value.\n",
    "    metrics = pd.DataFrame({\n",
    "        'k': [k],\n",
    "        'precision_favor': [report.iloc[0]['precision']],\n",
    "        'precision_against': [report.iloc[1]['precision']],\n",
    "        'precision_none': [report.iloc[2]['precision']],\n",
    "        'recall_favor': [report.iloc[0]['recall']],\n",
    "        'recall_against': [report.iloc[1]['recall']],\n",
    "        'recall_none': [report.iloc[2]['recall']],\n",
    "        'f1_against': [report.iloc[0]['f1-score']],\n",
    "        'f1_favor': [report.iloc[1]['f1-score']],\n",
    "        'f1_none': [report.iloc[2]['f1-score']],\n",
    "        'f1_macro_avg': [report.iloc[4]['f1-score']],\n",
    "        'f1_weighted_avg': [report.iloc[5]['f1-score']],\n",
    "        'semeval_macro_f1': [(report.iloc[0]['f1-score'] + report.iloc[1]['f1-score']) / 2]\n",
    "    })\n",
    "\n",
    "    # Accumulate the current report in the all_reports DataFrame.\n",
    "    all_metrics = pd.concat([all_metrics, metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.sort_values(\"semeval_macro_f1\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
